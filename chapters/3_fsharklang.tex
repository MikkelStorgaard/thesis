\chapter{The \fshark{} subset}
\label{chap:fsharklanguage}
In the following chapter, we will describe the \fshark{} subset. Although the
subset is just a part of \fsharp{}, we will describe it as if it was a language
itself.

Figures \cref{fig:fsharkstatements} shows the statements available in \fshark{}, 


\begin{figure}
  \centering
  \begin{tabular}{lclr}
    $prog$ & $::=$ & $module\ prog$ & \\
           & $|$   & $prog'\ prog$  & \\
           & $|$   & $\epsilon$     & \\

    $prog'$ & $::=$ & $typealias$   & \\
            & $|$   & $fun$ & \\

    $progs'$ & $::=$ & $prog'\ progs'$   & \\
             & $|$   & $\epsilon$ & \\
    \\
    $typealias$ & $::=$ & $\texttt{type}\ v\ = t $& \\
    $module$ & $::=$ & $\texttt{module}\ v = prog'\ progs'$ & \\
    \\
    $fun$ & $::=$ & \texttt{[<FSharkEntry>]} $\texttt{let}\ id\ (v_1 : t_1)\ \ldots\ (v_n : t_n) : t = e$ & \\
        & $|$   & $\texttt{let}\ v\ (v_1 : t_1)\ \ldots\ (v_n : t_n) : t' = e,$ & \\
        &       & \hspace{1em} \textit{(for any $i \in {1..n}$, $t_i$ is not a tuple)} \\
    \\

  \end{tabular}
  \caption{\fshark{} statements}
  \label{fig:fsharkstatements}
\end{figure}



\begin{figure}
  \centering
  \begin{tabular}{lclr}
    $e$ & $::=$ & $(e)$ & Expression in parens \\
        & $|$   & $k$ & Constant \\
        & $|$   & $v$ & Variable \\
        & $|$   & $(e_0,~\ldots,~e_n)$ & (Tuple expression) \\
        & $|$   & $\{\texttt{id}_0=e_0 ; \ldots ; \texttt{id}_n=e_n\}$ & (Record expression) \\
        & $|$   & $[\vert e_0 ; \ldots ; e_n\vert]$ & (Array expression) \\
        & $|$   & $v.[e_0] \ldots .[e_n]$ & (Array indexing) \\
        & $|$   & $v.id$ & (Record indexing) \\
        & $|$   & $v.id$ & (Module indexing) \\
        & $|$   & $e_1 \odot e_2$ & (Binary operator) \\
        & $|$   & $-e$ & (Prefix minus) \\
        & $|$   & \texttt{not} $e$ & (Logical negation) \\
        & $|$   & \texttt{if} $e_1$ \texttt{then} $e_2$ \texttt{else} $e_3$ & (Branching) \\
        & $|$   & \texttt{let} $p = e_1$ \texttt{in} $e_2$ & (Pattern binding) \\
        & $|$   & $\mathtt{fun}~p_0~\ldots~p_n~\mathtt{->}~e$ & (Anonymous function) \\
        & $|$   & $e_0~e_1$ & (Application) \\

    \\
  \end{tabular}
  \caption{\fshark{} expressions}
\label{fig:fsharkexpressions}
\end{figure}

\begin{figure}
  \centering
  \begin{tabular}{@{}lclr}
    $p$ & $::=$ & $id$ & (Name pattern) \\
        & $|$   & $(p_0, \ldots, p_n)$ & (Tuple pattern) \\
  \end{tabular}
  \caption{\fshark{} patterns}
\label{fig:fsharkpatters}
\end{figure}



\begin{figure}
  \centering
  \begin{tabular}{@{}lclr}
    $t$ & $::=$ & $\texttt{int8}~|~\texttt{int16} ~|~ \texttt{int} ~ |~\texttt{int64} $ & (Integers) \\
        & $|$   & $\texttt{uint8} ~ | ~\texttt{uint16} ~|~\texttt{uint} ~|~\texttt{uint64} $ & (Unsigned integers) \\
        & $|$   & $\texttt{single} ~| ~\texttt{double}$ & (Floats) \\
        & $|$   & $\texttt{bool}$ & (Booleans) \\
        & $|$   & $(t_0 * \ldots * t_n)$ & (Tuples) \\
        & $|$   & $\{id_0:t_0;~\ldots;~id_n:t_n\}$ & (Records) \\
        & $|$   & $t~\mathtt{array}$& (Arrays) \\
    \\
  \end{tabular}
  \caption{\fshark{} types}
\label{fig:fsharktypes}
\end{figure}

\begin{figure}
  \centering
  \begin{tabular}{@{}lclr}
    $k$ & $::=$ & $n\lit{y}~|~n\lit{s}~|~n~|~n\lit{L}$ & (8-, 16-, 32- and 64 bit signed integers) \\
        & $|$   & $n\lit{uy}~|~n\lit{us}~|~n~|~n\lit{UL}$ & (8-, 16-, 32- and 64 bit unsigned integers) \\
        & $|$   & $d\lit{f}~|~d $ & (Single and double precision floats) \\
        & $|$   & $true~|~false$ & (Boolean) \\
        & $|$   & $(k_0 ,~\ldots ,~k_n)$ & (Tuple) \\
        & $|$   & $\{id_0=k_0;~\ldots;~id_n=k_n\}$ & (Record) \\
        & $|$   & $[\vert k_0 ; \ldots ; k_n\vert]$ & (Array) \\
    \\
  \end{tabular}
  \caption{\fshark{} literals}
\label{fig:fsharkliterals}
\end{figure}
\clearpage

\subsection*{\fsharp{} operators available in \fshark{}}
The \fsharp{} subset chosen for \fshark{} is described in this subsection.
\begin{figure}[h]
  \centering
\begin{description}
\item[Arithmetic operators]\hfill\\
  The set of supported arithmetic operators is addition (\texttt{+}),
  binary subtraction and unary negation (\texttt{-}), multiplication
  (\texttt{*}), division (\texttt{/}) and modulus (\texttt{\%}).
  
\item[Boolean operators]\hfill\\
  \fshark{} currently supports logical AND (\texttt{\&\&}), logical OR
  (\texttt{$||$}), less- and greater-than (\texttt{<}, \texttt{>}), less- and
  greater-or-equal (\texttt{<=}, \texttt{>=}), equality (\texttt{=}),
  inequality (\texttt{<>}) and logical negation (\texttt{not}).

\item[Special operators]\hfill\\
  \fshark{} also supports some of \fsharp{}s syntactic sugar. These operators
  might not have direct Futhark counterparts, but their applications can be
  rewritten in Futhark for equivalent functionality.
  The supported operators are back- and forward pipes (\texttt{<|} and
  \texttt{|>}), and the range operator ($e_0$ \texttt{..} $e_1$), which
  generates the sequence of numbers in the interval $[e_0,e_1]$. Note that in
  \fshark{}, the range operator must be used inside an array as so
  \texttt{[|$e_0$..$e_1$|]} so we adhere to using arrays and not lists in our
  \fshark{} programs.
\end{description}
  \caption{\fshark{} operators}
  \label{fig:fsharkops}
\end{figure}
Note that all of these operators are overloaded and defined for all integer
and floating point types in \fsharp{}.



\subsection*{\fsharp{} standard library functions available in \fshark{}}
\fshark{} supports a subset of the \fsharp{} standard library. These are
functions that are imported in \fsharp{} modules by default.

\begin{figure}[h]
  \centering
\begin{description}
\item[\texttt{id}]\hfill\\
  The identity function.

\item[Common math function]\hfill\\
  The square root function (\texttt{sqrt}), the absolute value (\texttt{abs}),
  the natural exponential function (\texttt{exp}), the natural- and the decimal
  logarithm (\texttt{log} and \texttt{log10}).
  
\item[Common trigonometric functions]\hfill\\
  Sine, cosine and tangent functions (both standard and hyperbolic):
  \texttt{sin}, \texttt{cos}, \texttt{tan}), \texttt{sinh}, \texttt{cosh} and \texttt{tanh}.
  Also one- and two-argument arctangent: \texttt{atan} and \texttt{atan2}.

\item[Rounding functions]\hfill\\
  \fshark{} supports all of \fsharp{}s rounding functions:
  \texttt{floor}, \texttt{ceil}, \texttt{round} and \texttt{truncate}.
  
\item[Number convertion functions]\hfill\\
  \fshark{} supports all of \fsharp{}s number convertion functions.
  For all the following functions $t$, $t e = e', e : t_0, e' : t$, barring
  exceptions like trying to convert a too large 64-bit integer into a 32-bit
  integer.

  The convertion functions available are \texttt{int8}, \texttt{int16}, \texttt{int}, \texttt{int64}, \texttt{uint8}, \texttt{uint16},
  \texttt{uint}, \texttt{uin64}, \texttt{single}, \texttt{double}, \texttt{bool}.
  
\item[Various common number functions]\hfill\\
  \texttt{min}, \texttt{max}, \texttt{sign} and \texttt{compare}.
\end{description}
  \caption{\fshark{} operators}
  \label{fig:fsharkfuns}
\end{figure}

Currently, bitwise operators like bitwise-AND and bitwise-OR are missing, but
they should be relatively simple to add to the \fshark{} subset, by adding them
to the set of supported operators in the \fshark{} compiler.

\subsection*{On the \fsharp{} subset selected for \fshark{}}
For selecting the \fsharp{} subset to support in \fshark{}, I chose to look at
what functions that were included in \fsharp{}'s prelude. That is, the
functions that are available in an \fsharp{} program without having to
\texttt{open} their containing module first.
Fortunately, \fsharp{} opens several modules by default of which I only
needed to look in two different ones, to be able to support a reasonable amount
of \fsharp{} built-ins in \fshark{}.

The primary module used in my supported \fsharp{} subset is the module
\texttt{FSharp.Core.Operators}.
This module contained not only the standard arithmetic described in figure
\ref{fig:fsharkops}, but also most\footnote{except for some convertion
  functions, found in \texttt{FSharp.Core.ExtraTopLevelOperators}} of the functions shown in the figure \ref{fig:fsharkfuns}.
Except for \texttt{unit} type functions like \texttt{failwith}, \texttt{exit}
and \texttt{async}, most of the functions and operators
\texttt{FSharp.Core.Operators} have direct counterparts in Futhark's prelude,
with equivalent functionality: All except for four of operators and functions chosen for
\fshark{} are in fact implemented in Futhark's \texttt{math.fut} library.
It was therefore aan obvious decision to support these functions and operators in
\fshark{}.

However, for the remaining four functions, that didn't have equivalents in
Futhark's \texttt{math.fut}, their function calls are replaced with their
identities instead.
In example, whereas the \fshark{} code
\begin{minted}{ocaml}
  exp x
\end{minted}
is written in Futhark as 
\begin{lstlisting}[language=Futhark]
  exp x
\end{lstlisting}
because the exp function is also available in \texttt{math.fut}, the \fshark{}
code
\begin{minted}{ocaml}
  cosh x
\end{minted}
is rewritten as the full hyperbolic sine function instead, as so
\begin{lstlisting}[language=Futhark]
  ((exp x) + (exp (-x))) / 2.0
\end{lstlisting}
These rewritings are not pretty to look at from a programmer's perspective, but
\fshark{}s Futhark code is not meant to be read by humans anyhow.

(MAYBE INVESTIGATE WHETHER INLINING THESE HAS PERFORMANCE PENALTIES) 

% i could have also supported limited imports

\subsection*{The correctness of the \fshark{} subset.}
When transpiling code from one language to another, it is absolutely vital that
the programmer can trust, that the resulting code in the target language is
semantically equivalent to the source code.
In \fshark{}s case, it means that any program written using the \fshark{}
subset, must have the same result no matter whether it is run natively as
\fsharp{} code, or it is run as \fshark{} compiled Futhark code.

I.e., one could imagine a programming language which had defined the function
\texttt{log} not as the natural logarithm, but instead the binary logarithm. In
such a case, the translation from that language to Futhark would still go
without a hitch, and without any type errors to hint at the impending
catastrophe.
However, the native result with the Futhark result would be wildly different.

To ensure that every operator and function in the \fshark{} subset has
equivalent results, no matter whether the \fshark{} code is run as native
\fsharp{} code, or compiled into Futhark, I have written a test suite with unit
tests for each element in the \fsharp{} subset. 


(THESE ARE NOT ACTUALLY DONE YET)
(Are unit tests enough?)

all convertion functions pass through i64. this might be a mistake, as real
supports f32 to f64

thoughts on correctness of translations
testing correctness of these translations


\chapter{FSharkPrelude}
Besides defining an \fsharp{} subset suitable for Futhark translation, it was
also imperative to create a library of SOACs and array functions for \fshark{},
to make it possible to write programs with parallel higher-order array
functions.

Similarly to how the subset of math functions chosen from \fsharp{} to include in
the \fshark{} was chosen, the SOACs and array function included in the
\texttt{FSharkPrelude} has been picked directly from the Futhark libraries
\texttt{futlib/array.fut} and \texttt{futlib/soacs.fut}. The \texttt{FSharkPrelude} doesn't
discriminate between array functions and SOACs, as maintaining and importing two
different prelude files in \fshark{} was needlessly complicated.

The \texttt{FSharkPrelude} consists of functions which are directly named after
their Futhark counterparts, and have equivalent functionality.
This prelude, together with the \fshark{} subset, is what makes up the \fshark{} language.
When \fshark{} developers are writing modules in \fshark{}, they are guaranteed
that their \fshark{} programs has the same results, no matter whether their
programs are executed like native \fsharp{} code, or compiled and executed as
Futhark.

The \texttt{FSharkPrelude} versions of Futhark functions are defined in three
different ways.
\begin{enumerate}
  \item Functions like the SOAC \texttt{map} and the array function
    \texttt{length} have direct \fsharp{} equivalents, and are therefore
    implemented as calls to \texttt{Array.map} and \texttt{Array.length}
    respectively.
    For \texttt{map} for example, we have the following definition:
    \begin{minted}{fsharp}
let Map f aa = Array.map f aa
    \end{minted}

  \item Some Futhark SOACs, like \texttt{reduce}, takes a neutral element as one of the
    arguments in their function calls, whilst their \fsharp{} counterparts
    (\texttt{Array.reduce}) does only take an operator and an array as
    arguments.
    To define the \fshark{} SOAC so that it is equivalent to the Futhark
    version, it has been defined as so:
\begin{minted}{fsharp}
let Reduce (op: 'a -> 'a -> 'a) (neutral : 'a) (xs : 'a array) =
  let xs' = Array.append [|neutral|] xs
  in Array.reduce op xs'
\end{minted}

    Other functions, like the \texttt{map} functions which takes multiple arrays as
    arguments, require a bit of assembly first. For those \texttt{map} functions,
    we zip the arguments before using \texttt{Array.map} as usual:
\begin{minted}{fsharp}
let Map5 f aa bb cc dd ee =
  let curry f (a,b,c,d,e) = f a b c d e
  let xs = Zip5 aa bb cc dd ee
  in Array.map (curry f) xs
\end{minted}

    \item Lastly, some functions does not have \fsharp{} counterparts. In
      example, we implement \texttt{scatter} using a for-loop:
\begin{minted}{fsharp}
let Scatter (dest : 'a array) (is : int array) (vs : 'a array) : 'a array =
  for (i,v) in Zip is vs do
    dest.[i] <- v
  dest
      \end{minted}
\end{enumerate}
The complete list of available SOACs and array functions is available in
appendix \ref{appendix:soacs}.

Note that calls to \texttt{FSharkPrelude} functions are caught and exchanged for
Futhark functions during the \fshark{} compilation, as described in sec \ref{kig
  kig}.

% descriptions


% WHY ALL OF THIS
\subsection*{Why is FSharkPrelude part of the \fshark{} language?}
Several of Futhark's SOACs, such as \texttt{map}, already has \fsharp{}
versions that are directly equivalent.

But there are several issues with just letting the \fshark{} programmer use 
But many of these \fsharp{} functions are
contained in 
HER KOMMER DER MERE

 1) it would be awkward to maintain a whitelist of accepted library functions,
 instead of simply handing the developer a gated library.
 1½) uncomfortable to be told function is not supported at runtime 

 2) some Array functions have subtle differences compared to their
 futhark counterparts. In example, reduce doesn't take a neutral element which
 Futhark's reduce does.

 3)


 note; FSharkPrelude cannot detect bad operators in reduce. non-commutative ops
 in reduce goes bad when parallel, så deeeeeet


 some implementations, like ZipN, are probably criminally ineffective.

 \subsection*{How \fshark{} SOACs differ from Futhark's ditto}
On a surface level, \fshark{} and Futhark SOACs are the same. After all, they
have equivalent functionality.
However, Futhark's SOACs gets special treatment in the Futhark compiler, and are
fused together where applicable.
Take for instance the short code example in figure \ref{fig:futharkfusion}.

\begin{figure}[h]
  \centering
\begin{lstlisting}[language=Futhark]
entry main : []f32 =
  let xs = iota 100
  let ys = map (f32.i32) xs
  let zs = map (+ 4.5f32) ys
  in zs
\end{lstlisting}
  \caption{A short Futhark program consisting of just SOACs}
  \label{fig:futharkfusion}
\end{figure}

For non-OpenCL programs, Futhark's compiler fuses all three expressions into one for-loop, as described
in simplified Futhark \csharp{} code in figure \ref{fig:pseudofusion}.
Similarly, in an OpenCL program, the short code example is translated into a
single kernel, as shown in figure \ref{fig:pseudokernel}.

\begin{figure}[h]
  \centering
\begin{minted}{csharp}
float[] mem = new float[100];
for (int i = 0 ; i < 100 ;i++)
{
  float res = int_to_float(i);
  res = res + 4.5f;
  mem[i] = res;
}
\end{minted}[h]
  \caption{Figure \ref{fig:futharkfusion} compiled as (simplified) non-OpenCL
    \csharp{} code.}
  \label{fig:pseudofusion}
\end{figure}

\begin{figure}
  \centering
\begin{minted}{cpp}
__kernel void map_kernel(__global unsigned byte *mem)
{
   int global_thread_id = get_global_id();
   bool thread_active = global_thread_id < 100;

   float res;

   if (thread_active) {
       res = int_to_float(global_thread_id);
       res = res + 4.5f;
   }
   if (thread_active) {
       *(__global float *) &mem[global_thread_id * 4] = res;
   }
};
\end{minted}
  \caption{Figure \ref{fig:futharkfusion}, but compiled as a simplified OpenCL kernel.}
  \label{fig:pseudokernel}
\end{figure}


In both of the compiled examples, we must first allocate a target array for our
result, but note that although we obtain three different arrays in the original
Futhark code, both of the compiled versions transform the \texttt{iota}
expression into a for-loop instead, and inserts the operators from the two
subsequent \texttt{map}s into the loop.

This is a concrete implementation Futhark fusion rules as defined in \cite{pldi17}; which states
that $(map~f) \circ (map~g) \equiv map (f \circ g)$

However, executing \fshark{} code as native \fsharp{} code will execute the
expressions as written, which means that we are allocating and writing to an
array three times, once for each line in the program.

\subsubsection*{Futhark and nested maps}
Futhark's compiler also specializes in parallelizing nested SOAC
calls\cite{pldi17}, which in example transforms nested \texttt{map} expressions into one
single \texttt{map} expression. For Futhark programs like the one in figure
\ref{fig:fsharpnested}, the resulting OpenCL program contains a single map
kernel with $i * j$ active threads.

\begin{figure}[h]
  \centering
\begin{minted}{fsharp}
let xss = map (\row ->
              map (fun col ->
                row * col
              ) <| iota j
          ) <| iota i
\end{minted}
  \caption{A nested \fshark{} program}
  \label{fig:fsharpnested}
\end{figure}

The \fsharp{} compiler doesn't make any such transformations for \fshark{} programs.

\subsection*{Arguing for Futhark-equivalent functionality}
using a test suite with both positive and negative testing

\section{Arrays in \fsharp{} versus in Futhark}
As Futhark is an array language, designing the array handling for \fshark{} was
a non-inconsequential part of the design process.
Whereas multidimensional arrays in Futhark are written as i.e. \texttt{[][]i32}
for a two dimensional integer array, their actual representation in the compiled
code is a flat array of bytes, and an array of integers denoting the lengths of
the dimensions.
Accessing the array at runtime can be done in $O(1)$, whether it's
either at some constant or a variable index (i.e. \texttt{let second\_x = xs[2]} or \texttt{let n = xs[i,j]}).
The indexes are resolved during the Futhark compilation, either as scalars, or
as a variable calculated from other variables.

RESEARCH WHETHER ``RANDOM READS'' ARE COALESCED IN A NICE WAY IN FUTHARK.

Functional languages like Haskell and \fsharp{} mainly works with lists.
In \fsharp{}, lists are implemented as singly linked lists. Nodes in the
list are dynamically allocated on the heap, and lookups take $O(n)$ time.
We cannot make multidimensional lists, but we can make lists of lists: If we
were to emulate a two dimensional list of integers in \fsharp{}, we could use
the type \texttt{int list list}. At runtime, the type would then be realized as
a singly linked list of references to singly linked list of integers.
For an \texttt{int list list} of $i \times j$ integers, we therefore have
lookups in $O(i+j)$ time.

\fsharp{} does also have arrays. The \texttt{System.Array} class itself is reference
type. If we initialize an integer array in FSharp like so: \texttt{let arr =
Array.create 10 0}, the type of \texttt{arr} is a reference to where it's corresponding
array is located in memory. As the integers contained in the array are value
types, the layout of the array referenced by \texttt{arr} is some initial array
metadata, and then the ten integers stored in sequence.

We can access the array elements on $O(1)$ time, as indexing into the array is
just done by accessing the array reference plus an index offset.
If we want to emulate multidimensional arrays with these elements, we can create
arrays of arrays (in .NET terms, these are called ``jagged arrays''). In figure
\ref{fig:jaggedarrayfsharp} we initialize a jagged array of integers.

\begin{figure}[h]
  \centering
\begin{minted}{fsharp}
let i = 8
let j = 5
let xss = Array.init i <| (Array.create j) 
  
(* xss = [|
           [|0;0;0;0;0|];
           [|1;1;1;1;1|];
           [|2;2;2;2;2|];
           [|3;3;3;3;3|];
           [|4;4;4;4;4|];
           [|5;5;5;5;5|];
           [|6;6;6;6;6|];
           [|7;7;7;7;7|];
         |]
*) 

let some_two = xss.[2].[3]

\end{minted}
  \caption{Initializing a jagged array of integers in FSharp}
  \label{fig:jaggedarrayfsharp}
\end{figure}

\texttt{xss} is an array of arrays, so \texttt{xss} is a reference to an array
in memory, which itself contains references to other arrays.
To retrieve the variable \texttt{some\_two}, we first follow the reference to
the array \texttt{xss} in memory. There we get the second element, which is a
reference to another array in memory. In this array, we read the third element,
which in this case is the 2 that we wanted.

The lookup takes $O(d)$ time\footnote{where $d$ is the number of references we
  we are chasing to get our element.}, as we access arrays in $O(1)$ time, and have to follow $d$
references to get to our element. If we just wanted a reference to the second
array in \texttt{xss}, we would be chasing the first reference to \texttt{arr},
and then return one of the references stored within.

FSharp also offers actual multidimensional arrays.
Instead of  by initiabb DO MORE HERE


comparison between arrays: multidims are represented as single objects in
memory, less cache misses. 
and so forth

\\

WE HAVE NO WAY OF KNOWING WHERE THINGS ARE ALLOCATED

SHOULD WE LOOK AT PERFORMANCE OR LANGUAGE DESIGN FIRST?


\section{Converting jagged arrays to Futhark's flat arrays,  and back again}
As mentioned in section \ref{csharpentries}, we cannot just pass jagged arrays
as arguments to the Futhark \csharp{} entry functions.
Instead, we must convert our jagged array into a flat array and an array of
integers, and pass these two objects as arguments instead.

\subsection{Analysis of FlattenArray}
The simple algorithm for this flattening is described in pseudocode in figure
\ref{fig:flattenarray}. The implemented algorithm is slightly more complex, as
it has perform various type castings, and also checks for invalid arrays such as
irregular arrays.
The implemented algorithm is available in the appendices.

When FlattenArray first is called with a jagged array as input, we don't know
how many dimensions this array has. Therefore, we recursively call FlattenArray
on the subarrays of the arrays, until these recursive calls reach a base case.
The base case is the array that does not contain array references, but primitive
values.

\begin{description}
\item[\texttt{L2}]: For a one dimensional jagged array, this branch is taken once.
  For a jagged array of $d$ dimensions, it's taken
  $\mathlarger{\prod_{n=1}^{d-1}(\text{subarrays at }d_n)}$ times.

\item[\texttt{L3}] is the base case, which takes $O(1)$ time. This is because we
are just returning a tuple with the original array, and singleton array that holds the length of the
array (creating the singleton array is also $O(1).$)

\item[\texttt{L4}]:
  For a jagged array of $d$ dimensions, this branch is taken
  $\mathlarger{\prod_{n=1}^{d-1}(\text{subarrays at }d_n)}$ times.

\item[\texttt{L5}] is the start of the recursive case. This line is called
  $O(d)$ times, $d$ being the number of dimensions in the jagged array.
  The result of \texttt{map FlattenArray array} is an array of \texttt{a} array references
  and integer array references.

\item[\texttt{L6}] MORE HERE
\item[\texttt{L7}] simply retrieves a reference to the first array in the array
  of subarray lengths. This is $O(1)$.
\item[\texttt{L8}] is by far the most costly line in the function.
  \fsharp{}s \texttt{Array.concat} function takes a sequence of arrays,
  allocates a new array, and copies each element of the old arrays into the new array.
  Each of the $n$ elements in the jagged array is copied to a new array a maximum of $d$
  times, which means we are performing $O(n*d)$ reads and writes.
  
\item[\texttt{L9}] retrieves the length of an array, and is $O(1)$.

\item[\texttt{L10}] appends a singleton array to the accumulated array of
  subarray dimensions, by first creating a singleton array, and then copy both
  the single element and the contents of the accumulated array to a third array
  of their collected length.
\end{description}

All in all, the upper bound on the \texttt{FlattenArray} algorithm is $O(n*d)$.
This is a far cry from the performance of flattening in Futhark. Flattening is
done in $O(1)$, as flattening merely calculates the product of the dimensions of
the array, and returns the result as the new single dimension of the array.


\begin{figure}[h]
  \centering
\begin{minted}[linenos]{text}
FlattenArray (array : Array of a) : (Array of b * Array of int) =
  if a is not (Array of a):
    return (array, [len(array)])
  else:
    subarrays_and_lengths = map FlattenArray array
    (subarrays, subarrays_lengths) = unzip subarrays_and_lengths
    subarray_lengths = head(subarrays_lengths)
    concatenated_subarrays = concat subarrays
    this_length = len(array)
    lengths = [this_length] @ subarray_lengths
    return (contatenated_arrays, lengths)
\end{minted}
  \caption{Flattening jagged arrays, pseudocode}
  \label{fig:flattenarray}
\end{figure}

\subsection{Analysis of UnflattenArray}
The algorithm \texttt{UnflattenArray} in figure \ref{fig:unflattenarray}
restores the flat array from the Futhark \csharp{} program, to a jagged array in \fsharp{}.
Like in \texttt{FlattenArray}, the most expensive line in the function is the
array-manipulating one. In \texttt{UnflattenArray}, it is line 7: For each
dimension in the lengths array, we chunk our data array into multiple smaller
arrays. Each of the $n$ elements in the initial array is moved to a new and smaller array
$d$ times, which makes the complexity of this algorithm $O(n*d)$.

\subsubsection*{Why UnflattenArray hinders a specific tuple type}
When an \fshark{} function is invoked, it's arguments are prepared by an
argument converter first. For scalar arguments, the argument is simply returned.
But for array arguments, we must flatten the jagged array into a tuple that
follows Futhark's array representation.

When the Futhark function returns, we then have to unflatten the Futhark arrays
back into jagged arrays. To do this, we naively look at all the values
returned by the Futhark function, and whenever we encounter a tuple of type
\texttt{('a [] * int64 [])}, we assume that this is a flat array that needs to
be unflattened.
This procedure works fine, but has one side effect: \fshark{} doesn't support
entry functions that has (\texttt{('a [] * int64 [])}) tuples in their return
types, because this type is reserved.

To circumvent this, the user is instead encouraged to return the tuple as two
separate values.

\begin{figure}[h]
  \centering
\begin{minted}[linenos]{text}
UnflattenArray (lengths : Array of int) (data : Array of a) =
  if len(lengths) = 1:
    return data
  else:
    length = head(lengths)
    lengths' = tail(lengths)
    data' = chunk_array length data 
    data'' = map (UnflattenArray lengths') data'
    return data''
\end{minted}
  \caption{Recreating a jagged array from flat array with dimensions}
  \label{fig:unflattenarray}
\end{figure}

\subsection*{An alternative solution (FSharkArrays)}
How they work

How they would alleviate the problem

Why they weren't chosen anyhow (hint; needing to pepper FSharkArray all over
code, would stand in way of idiomatic FSharp style)

\subsection*{Conclusion on arrays}
Ultimately, choosing between jagged arrays, multidimensional arrays and
FSharkArrays became a question of simplicity vs. performance.
For \fshark{}, I had the liberty to focus solely on simplicity, as \fshark{}
code is neither intended or even efficient when executed as native FSharp code.
Therefore I could choose to let \fshark{} use jagged arrays, instead of any of
the other options.

The syntax for declaring a jagged array type closely
resembles Futhark's multidimensional array syntax (take for instance FSharp's
\texttt{int [] []} versus Futhark's \texttt{[][]i32} for declaring
two-dimensional integer arrays).
The close similarities between Futhark and \fshark{} code means that \fshark{}
generated Futhark code is easier to read for debugging purposes, and likewise
makes Futhark code easier to port to \fshark{}.

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End: