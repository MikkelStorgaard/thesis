\chapter{Evaluation and benchmarks}
In this chapter we first evaluate both the correctness of our code generator,
and the performance of the \csharp{} programs that our code generator generates.
For testing correctness, we use the Futhark compiler's existing test suite with
our new code generator. For the performance evaluation, we run and compare benchmark
results between programs generated by the Futhark \csharp{}-, \clang{}- and \Python{} code generators.

We then evaluate whether the \fshark{} language succeeds in letting us write
complex GPU benchmarks in an idiomatic \fsharp{} style.

Finally, we evaluate the \fshark{} compiler itself. First we test whether the
\fshark{} compiler correctly translates \fshark{} programs to Futhark, so that
they are functionally equivalent.
We then compile and compare the performance of GPU benchmarks written in
\fshark{} with equivalent benchmarks written in Futhark.
\subsubsection*{Specifications for benchmark}
For all benchmarks in this section, we have run the benchmarks on a system with
these attributes:
\begin{itemize}
\item CPU: 4 cores of Intel Core i5-6500 at 3.20GHz
  \begin{itemize}
  \item L1 cache: 128 KiB 
  \item L2 cache: 1024 KiB 
  \item L3 cache: 6144 KiB 
  \end{itemize}
\item GPU: GeForce GTX 970
\end{itemize}

\section{Correctness of the Futhark csharp{} generator}
\label{subsec:futharkcsharpcorrectness}
To show that the Futhark \csharp{} code generator correctly translates Futhark
to \csharp{} programs, we have chosen to test our solution using the already existing Futhark test
suite, as described in section~\ref{sec:errorsintheimplementation}.

Although the \csharp{} code generator currently \textit{does not} pass all the
tests in the test suite, we believe that the Futhark-to-\csharp{} translation
itself is correct.

However, there are still parts of the generated Futhark \csharp{} programs which
contains errors. Therefore we cannot say that the current implementation is
completely correct.

\section{The performance of Futhark \csharp{} programs}
\label{subsec:futharkcsharpperformance}
To determine whether Futhark \csharp{} programs have similar performance to
Futhark C and Futhark Python programs, we have used Futhark's own benchmark
suite.
We have measured the runtime of 22 benchmarks compiled with the Futhark
\csharp{} code generator, and used the performance of the Futhark
\clang{}-\texttt{OpenCL}-generated kernels as a reference point.\\
The results are shown in table~\ref{table:csharpbenchmarks}.

We have sorted the benchmarks by their runtimes.
Short benchmarks are easily influenced by ``background noise'' from the
operating system, whereas small fluctutations in running time has much less
effect on longer running benchmarks.

Our benchmarks doesn't show that either the \csharp{} or the \clang{} GPU
kernels are the better choice to any significant degree.
For the two longest benchmarks, we see that the \csharp{} kernels do run
faster than the reference, but not more than $\sim 3\%$. For the remaining
benchmarks, the two versions are mostly comparable. We see a large speed
difference for the \texttt{Hotspot} benchmark, but it also has a high relative
standard deviation.

As we go further down the list we also see that \texttt{BFS Iterative Partitioning} and
\texttt{NN} have large speed differences, without much relative standard
deviation. However, at this point we are running benchmarks that lasts for few
milliseconds, so we will not investigate the difference further.

On the grounds of these benchmarks, we are confident that our \csharp{} code
generator is able to build \csharp{} programs that are comparable in performance
to corresponding \clang{} versions.

However, as described in \ref{sec:errorsinbenchmark}, we are also aware that the
current implemention Futhark \csharp{} implementation contains errors, which for
some benchmarks makes it impossible to reliably measure their runtimes. We
still have more benchmarks to run when these errors are fixed, but we are
confident that future benchmarks will support our assertation, rather than
disprove it.

\begin{figure}[H]
	\begin{tabular}{l r r r r}
    \textbf{Benchmark} & \textbf{\csharp{}} & \textbf{Ref.} & \textbf{Speedup in percentage} & \textbf{RSD} \\
  \texttt{LocVolCalib}               & 1879302 &1940669 & $+ 3.16\%$ & 0.00 \\
  \texttt{Particle Filter}           & 396207 &412421 & $+ 3.93\%$ & 0.01 \\
  \texttt{Myocyte}                   & 395485 &396866 & $+ 0.35\%$ & 0.00 \\
  \texttt{Stencil}                   & 158911 &156194 & $- 1.74\%$ & 0.01 \\
  \texttt{OptionPricing}             & 153315 &154702 & $+ 0.9\%$ & 0.00 \\
  \texttt{LUD clean}                 & 131038 & 132479 & $+ 1.09\%$ & 0.00 \\
  \texttt{NW}                        & 62752 &62995 & $+ 0.39\%$ & 0.01 \\
  \texttt{BFS Flattened}             & 40708 &39384 & $- 3.36\%$ & 0.01 \\
  \texttt{Hotspot}                   & 34073 &44038 & $+ 22.63\%$ & 0.46 \\
  \texttt{BFS Padded}                & 30924 &33047 & $+ 6.42\%$ &0.06 \\
  \texttt{High Pass Filter (FFT)}    & 27156 &22252 & $- 22.04\%$& 0.02 \\
  \texttt{Radix-sort}                & 21805 &22462 & $+ 2.92\%$ & 0.02 \\
  \texttt{SRAD}                      & 13813 &13456 & $- 2.65\%$ &0.04 \\
  \texttt{Backprop}                  & 12576 &12887 & $+ 2.41\%$ &0.07 \\
  \texttt{Pagerank}                  & 8987 &8796 & $- 2.17\%$ &0.01\\
  \texttt{BFS Iterative Partitioning}& 7193 &6062 & $- 18.66\%$&0.04 \\
  \texttt{NN}                        & 7127 &8197 & $+ 13.05\%$&0.02 \\
  \texttt{BFS Heuristic}             & 6468 &6275 & $- 3.08\%$&0.02 \\
  \texttt{Fluid}                     & 1316 &1060 & $- 24.15\%$& 0.06 \\
  \texttt{LUD}                       & 570 &532 & $- 7.13\%$& 0.13 \\
  \texttt{Canny Edge Detection}      & 241 &202 & $- 19.31\%$&0.07 \\
  \texttt{Raytracer}                 & 218 &351 & $+ 37.89\%$&0.17 \\
  \caption{Average benchmark runtime in microseconds}
  \label{table:csharpbenchmarks}
\end{figure}

\begin{figure}[H]
  \centering
  \begin{tabular}{l l}
  \textbf{Benchmark} & \textbf{Dataset} \\
  \texttt{LocVolCalib} & large dataset \\
  \texttt{Particle Filter} & \texttt{128\_128\_10\_image\_400000\_particles.in} \\
  \texttt{Myocyte} & medium dataset \\
  \texttt{Stencil} & default dataset \\
  \texttt{OptionPricing} & large dataset \\
  \texttt{LUD Clean} & $2048 \times 2048$ \\
  \texttt{NW} & medium dataset \\
  \texttt{BFS Flattened}&\texttt{64kn\_32e-var-1-256-skew.in} \\
  \texttt{Hotspot} & $1024 \times 1024$ \\
  \texttt{BFS Padded} & \texttt{64kn\_32e-var-1-256-skew.in} \\
  \texttt{High Pass Filter (FFT)} & $1024 \times 1024$  \\
  \texttt{Radix-sort} & $N = 10^6$\\
  \texttt{SRAD} & \texttt{image.in} \\
  \texttt{Backprop} & medium dataset \\
  \texttt{Pagerank} & \texttt{random\_medium.in} \\
  \texttt{BFS Iterative Partitioning}&\texttt{64kn\_32e-var-1-256-skew.in} \\
  \texttt{NN} & medium dataset \\
  \texttt{BFS Heuristic} &\texttt{64kn\_32e-var-1-256-skew.in}  \\
  \texttt{Fluid} & medium dataset \\
  \texttt{LUD} & $64 \times 64$ \\
  \texttt{Canny Edge Detection} & Lena ($512 \times 512$) \\
  \texttt{Raytracer} & \textit{dataset \#0} \\
  \caption{Datasets used for benchmarks}
  \label{table:csharpbenchmarksdatasets}
\end{figure}

\section{Futhark \csharp{} integration in \csharp{} programs}
Our implemented code generator allows us to use Futhark libraries in \csharp{},
as expected. The example below is taken from the file \texttt{Program.cs} in the
\texttt{CSharpTest} folder in the \fshark{} repository.
In this folder, we find a compiled \csharp{} .dll file which is the result of
compiling the LocVolCalib benchmark with the \texttt{futhark-csopencl} compiler.
\begin{minted}[fontsize=\scriptsize, breaklines]{csharp}
using System;
using LocVolCalib;
namespace CSharpTest
{
    internal class Program
    {
        public static void Main(string[] args)
        {
            var lvc = new LocVolCalib.LocVolCalib(args);
            var res = lvc.main(256, 256, 256, 64, 0.03f, 5.0f, 0.6f, 0.5f, 0.2f);
            var result_array = res.Item1;
            Console.WriteLine(result_array);
        }
    }
}
\end{minted}
First we instantiate an instance of the LocVolCalib class from the Futhark
\csharp{} class with the arguments that we passed to the main method of our
Program class. This lets us pass flags to the LocVolCalib class, which for
example lets us specify the number of runs we want our benchmark to execute.

Then we run the benchmark by calling the \texttt{lvc.main} method as shown.
The program behaves as expected, and prints the benchmark results after the
benchmark run.

As discussed in section~\ref{subsec:flatarraysinentryfuncs}, the current return
type is cumbersome, but such is the current state of affairs.

\section{The design of the \fshark{} language}
\label{sec:fsharklanguageeval}
One of the goals of \fshark{} is to enable users to write complex GPU programs
using idiomatic \fsharp{} code.

To test this, we have taken two already existing benchmark implementations from
Futhark, and manually translated them to \fshark{}.
We will not elaborate on the functionality of the benchmarks in these two
examples. Instead we will focus on the code style used in \fshark{} programs.

\subsection{LocVolCalib}
\label{subsec:locvolcalib}
First, we present the \fshark{} version of the LocVolCalib benchmark (respectively
FSharpTests/Benchmarks/LocVolCalib.fs and finpar/LocVolCalib.fut in the
\fshark{} and Futhark benchmarks repository.) from the Finpar\cite{finpar}
benchmark suite.

We have chosen this benchmark as it is features plenty of nested SOACs, and is
in general a structurally complex program.

Below, we show multiple snippets of the \fshark{} and Futhark version of the
LocVolCalib benchmark to demonstrate
\begin{minted}[fontsize=\scriptsize, breaklines]{fsharp}
;; Snippet from FShark's LocVolCalib
let explicitMethod (myD:    float32 [] []) (myDD: float32 [] [])
                   (myMu:   float32 [] []) (myVar: float32 [] [])
                   (result: float32 [] [])
                  : float32 [] [] =
  // 0 <= i < m AND 0 <= j < n
  let m = Length myDD
  Map3 (fun (mu_row : float32 []) (var_row : float32 []) (result_row : float32 []) ->
    Map5 (fun (dx : float32 []) (dxx : float32 []) (mu : float32) (var : float32) (j : int) ->
      let c1 = if 0 < j
               then (mu*dx.[0] + 0.5f*var*dxx.[0]) * result_row.[j-1]
               else 0.0f
      let c3 = if j < (m-1)
               then (mu*dx.[2] + 0.5f*var*dxx.[2]) * result_row.[j+1]
               else 0.0f
      let c2 = (mu*dx.[1] + 0.5f*var*dxx.[1]) * result_row.[j]
      in  c1 + c2 + c3) myD myDD mu_row var_row <| (Iota m)
   ) myMu myVar result

// for implicitY: should be called with transpose(u) instead of u
let implicitMethod (myD:  float32 [] [])  (myDD:  float32 [] [])
                   (myMu: float32 [] [])  (myVar: float32 [] [])
                   (u:    float32 [] [])  (dtInv: float32)
                    : float32 [] [] =
  Map3 (fun (mu_row : float32 []) (var_row : float32 []) (u_row : float32 []) ->
    let (a,b,c) = Unzip3 (
      Map4 (fun (mu : float32) (var : float32) (d : float32 []) (dd : float32 []) ->
        (0.0f - 0.5f*(mu*d.[0] + 0.5f*var*dd.[0]), dtInv - 0.5f*(mu*d.[1] + 0.5f*var*dd.[1]), 
        0.0f   - 0.5f*(mu*d.[2] + 0.5f*var*dd.[2])
        )
      ) mu_row var_row myD myDD
    )
    in tridagPar a b c u_row
  ) myMu myVar u
\end{minted}

\begin{lstlisting}[language=Futhark, basicstyle=\footnotesize\ttfamily]
-- Snippet from Futhark's LocVolCalib
let explicitMethod [m][n] (myD:    [m][3]f32,  myDD: [m][3]f32,
                           myMu:   [n][m]f32,  myVar: [n][m]f32,
                           result: [n][m]f32)
                  : *[n][m]f32 =
  -- 0 <= i < m AND 0 <= j < n
  map3 (\mu_row var_row result_row ->
    map5 (\dx dxx mu var j ->
      let c1 = if 0 < j
               then (mu*dx[0] + 0.5*var*dxx[0]) * unsafe result_row[j-1]
               else 0.0
      let c3 = if j < (m-1)
               then (mu*dx[2] + 0.5*var*dxx[2]) * unsafe result_row[j+1]
               else 0.0
      let c2 =      (mu*dx[1] + 0.5*var*dxx[1]) * unsafe result_row[j  ]
      in  c1 + c2 + c3) myD myDD mu_row var_row (iota m)
  ) myMu myVar result

-- for implicitY: should be called with transpose(u) instead of u
let implicitMethod [n][m] (myD:  [m][3]f32,  myDD:  [m][3]f32,
                           myMu: [n][m]f32,  myVar: [n][m]f32,
                           u:   *[n][m]f32,  dtInv: f32)
                  : *[n][m]f32 =
  map3 (\mu_row var_row u_row  ->
    let (a,b,c) = unzip3 
      (map4 (\mu var d dd ->
        ( 0.0   - 0.5*(mu*d[0] + 0.5*var*dd[0])
        , dtInv - 0.5*(mu*d[1] + 0.5*var*dd[1])
        , 0.0   - 0.5*(mu*d[2] + 0.5*var*dd[2]))
      ) mu_row var_row myD myDD)
    in tridagSeq (a, copy b, c, copy u_row )
  myMu myVar u
\end{lstlisting}
There are a couple of differences. The Futhark version can define the lengths of
the dimensions of its arrays in the function definition. These lengths can then
be used as variables in the function body. An example of this is shown in the
Futhark example: At line 2 we define that our input arrays have $n*m$ elements,
or in some cases $3*m$, and we can then use these lengths, such as in the
if-expression on line 12.

The second difference is on line 31 of the Futhark version. Here, we copy the
array used for our function call, which is a feature used for Futhark's
uniqueness types\cite{pldi17}.
As we don't have uniqueness types in \fshark{}, we can leave out this copy in
the \fshark{} version, as shown in line 33.

The third difference is the usage of the \texttt{unsafe} expression in Futhark's
example at line 10, 13 and 15. We need them in Futhark to circumvent Futhark's
boundary checks for array indexing, but we can leave them out in the \fshark{}
version, as \fshark{} doesn't have that kind of boundary checks.

The second pair of snippets are shown below.

\begin{minted}[fontsize=\scriptsize, breaklines]{fsharp}
let value (numX: int) (numY: int) (numT: int) (s0: float32) (strike: float32) 
          (t: float32) (alpha: float32) (nu: float32) (beta: float32): float32 =
  let (myXindex, myYindex, myX, myY, myTimeline) = initGrid s0 alpha nu t numX numY numT
  let (myDx, myDxx) = initOperator myX
  let (myDy, myDyy) = initOperator myY
  let myResult = setPayoff strike myX myY
  let myTimeline_neighbours = Reverse (Zip (Init myTimeline) (Tail myTimeline))

  let myResult' = 
    Foldl (fun oldResult (tnow,tnext) ->
      let (myMuX, myVarX, myMuY, myVarY) =
        updateParams myX myY tnow alpha beta nu
      in rollback tnow tnext oldResult
            myMuX myDx myDxx myVarX
            myMuY myDy myDyy myVarY
      ) myResult myTimeline_neighbours
  in myResult'.[myYindex].[myXindex]
\end{minted}

\begin{lstlisting}[language=Futhark, basicstyle=\footnotesize\ttfamily]
let value(numX: i32, numY: i32, numT: i32, s0: f32, strike: f32, 
          t: f32, alpha: f32, nu: f32, beta: f32): f32 =
  let (myXindex, myYindex, myX, myY, myTimeline) =
    initGrid(s0, alpha, nu, t, numX, numY, numT)
  let (myDx, myDxx) = initOperator(myX)
  let (myDy, myDyy) = initOperator(myY)
  let myResult = setPayoff(strike, myX, myY)
  let myTimeline_neighbours = reverse (zip (init myTimeline) (tail myTimeline))

  let myResult = loop (myResult) for (tnow,tnext) in myTimeline_neighbours do
      let (myMuX, myVarX, myMuY, myVarY) =
        updateParams(myX, myY, tnow, alpha, beta, nu)
      let myResult = rollback(tnow, tnext, myResult,
                              myMuX, myDx, myDxx, myVarX,
                              myMuY, myDy, myDyy, myVarY)

      in myResult
  in myResult[myYindex,myXindex]
\end{lstlisting}
There are two major differences: First, the \fshark{} version doesn't take one
single tuple as the function argument, but does instead need to take the tuple
elements as arguments individually. This is because of the \fsharp{} compiler's
currying, as described in section~\ref{noteonfsharktypes}.

Second, we have translated the Futhark version's for loop on line 9 into a
\texttt{Foldl} on line 9 of the \fshark{} version. This is because the current
version of \fshark{} doesn't support \texttt{for-loops}.
Otherwise, the two expressions are equivalent.

The complete \fshark{} version is available in
appendix~\ref{app:fsharklocvolcalib}, with the Futhark version available for reference.

\subsection{nbody}
Below, we present the \fshark{} version of the nbody benchmark (respectively
FSharpTests/Benchmarks/nbody.fs and accelerate/nbody/nbody.fut in the
\fshark{} and Futhark benchmarks repository.) from the Accelerate\cite{Accelerate}
benchmark suite.

We have chosen this benchmark to show how matrix manipulation functions can be
implemented in \fshark{}, and how \fshark{} have support for type aliases and
records similar to Futhark.

The examples from the nbody benchmark are shown below:

\begin{minted}[linenos, breaklines, fontsize=\scriptsize]{fsharp}
// Snippet from FShark's nbody

module Vec3 =
    type Vec3single = {x:single ; y:single ; z:single}
    let plus (a : Vec3single) (b : Vec3single) : Vec3single =
        {x=a.x+b.x; y=a.y+b.y; z=a.z+b.z}
            
    let minus (a : Vec3single) (b : Vec3single) : Vec3single =
        {x=a.x-b.x; y=a.y-b.y; z=a.z-b.z}
        
    let dot (a : Vec3single) (b : Vec3single) : single =
        a.x*b.x + a.y*b.y + a.z*b.z
        
    let scale (a : single) (b : Vec3single) : Vec3single =
        {x=a*b.x; y=a*b.y; z=a*b.z}
        
    let norm (a : Vec3single) : single =
        sqrt <| a.x*a.x + a.y*a.y + a.z*a.z
        
    let normalise (v : Vec3single) : Vec3single =
        let l = norm v
        in scale (1.0f / l) v
        
type vec3 = Vec3.Vec3single
type mass = single
type position = vec3
type acceleration = vec3
type velocity = vec3

type body = { position: position;
              mass: mass;
              velocity: velocity;
              acceleration: acceleration
            }

// ...

let advance_body (time_step: single) (body: body) (acc: acceleration): body =
  let acceleration = Vec3.scale body.mass acc
  let position = Vec3.plus body.position <| Vec3.scale time_step body.velocity
  let velocity = Vec3.plus body.velocity <| Vec3.scale time_step acceleration
  in {position=position; mass=body.mass; velocity=velocity; acceleration=acceleration}

let advance_bodies (epsilon: single) (time_step: single) (bodies: body []): body [] =
  let accels = calc_accels epsilon bodies
  in Map2 (fun body acc -> advance_body time_step body acc) bodies accels

let advance_bodies_steps (n_steps: int) (epsilon: single) (time_step: single)
                             (bodies: body []): body [] =
  let steps = Iota n_steps
  in Foldr (fun _ bodies' -> advance_bodies epsilon time_step bodies') bodies steps

let wrap_body (posx : single) (posy : single) (posz : single) (mass : single) (velx : single)
              (vely : single) (velz : single) (accx : single) (accy : single) (accz : single)
              : body =
  {position={x=posx; y=posy; z=posz};
   mass=mass;
   velocity={x=velx; y=vely; z=velz};
   acceleration={x=accx; y=accy; z=accz}}

let unwrap_body (b: body): (single * single * single * single * single * single * single * single * single * single) =
  (b.position.x, b.position.y, b.position.z,
   b.mass,
   b.velocity.x, b.velocity.y, b.velocity.z,
   b.acceleration.x, b.acceleration.y, b.acceleration.z)

// ...

let rotatePointByMatrix (rotation: single [] []) (p: position): position =
  let x = p.x
  let y = p.y
  let z = p.z
  {x= x*rotation.[0].[0] + y*rotation.[1].[0] + z*rotation.[2].[0];
   y= x*rotation.[0].[1] + y*rotation.[1].[1] + z*rotation.[2].[1];
   z= x*rotation.[0].[2] + y*rotation.[1].[2] + z*rotation.[2].[2]}

let rotatePointsByMatrix (rotation: single [] []) (ps: position []): position [] =
  Map (rotatePointByMatrix rotation) ps

let rotateXMatrix (angle: single): single [] [] =
  [|
    [|1.0f;       0.0f;          0.0f|];
    [|0.0f;  cos angle;   - sin angle|];
    [|0.0f;  sin angle;     cos angle|]
  |]

let rotateYMatrix (angle: single): single [] [] =
  [|
    [|cos angle  ; 0.0f; sin angle|];
    [|0.0f       ; 1.0f; 0.0f     |];
    [|- sin angle; 0.0f; cos angle|]
  |]

let matmult (x: single [] []) (y: single [] []) : single [] [] =
  let Sum = Reduce (+) 0.0f
  Map (fun xr ->
        Map (fun yc -> Sum (Map2 (fun x y -> x*y) xr yc)) (Transpose y)
  ) x
\end{minted}

\begin{lstlisting}[language=Futhark, basicstyle=\footnotesize\ttfamily]
-- Snippet from Futhark's nbody
module vec3 = mk_vec3 f32

type mass = f32
type position = vec3.vec
type acceleration = vec3.vec
type velocity = vec3.vec
type body = {position: position,
             mass: mass,
             velocity: velocity,
             acceleration: acceleration}

let advance_body (time_step: f32) (body: body) (acc: acceleration): body =
  let acceleration = vec3.scale body.mass acc
  let position = vec3.(body.position + scale time_step body.velocity)
  let velocity = vec3.(body.velocity + scale time_step acceleration)
  in {position, mass=body.mass, velocity, acceleration}

let advance_bodies [n] (epsilon: f32) (time_step: f32) (bodies: [n]body): [n]body =
  let accels = calc_accels epsilon bodies
  in map2 (advance_body time_step) bodies accels

let advance_bodies_steps [n] (n_steps: i32) (epsilon: f32) (time_step: f32)
                             (bodies: [n]body): [n]body =
  loop bodies for _i < n_steps do
    advance_bodies epsilon time_step bodies

let wrap_body (posx: f32, posy: f32, posz: f32)
              (mass: f32)
              (velx: f32, vely: f32, velz: f32)
              (accx: f32, accy: f32, accz: f32): body =
  {position={x=posx, y=posy, z=posz},
   mass,
   velocity={x=velx, y=vely, z=velz},
   acceleration={x=accx, y=accy, z=accz}}

let unwrap_body (b: body): ((f32, f32, f32), f32, (f32, f32, f32), (f32, f32, f32)) =
  ((b.position.x, b.position.y, b.position.z),
   b.mass,
   (b.velocity.x, b.velocity.y, b.velocity.z),
   (b.acceleration.x, b.acceleration.y, b.acceleration.z))

//...

let rotatePointByMatrix (rotation: [3][3]f32) ({x,y,z}: position): position =
  {x= x*rotation[0,0] + y*rotation[1,0] + z*rotation[2,0],
   y= x*rotation[0,1] + y*rotation[1,1] + z*rotation[2,1],
   z= x*rotation[0,2] + y*rotation[1,2] + z*rotation[2,2]}

let rotatePointsByMatrix [n] (rotation: [3][3]f32)(ps: [n]position): [n]position =
  map (rotatePointByMatrix rotation) ps

let rotateXMatrix (angle: f32): [3][3]f32 =
  [[1f32,        0f32,         0f32],
   [0f32, f32.cos angle, -f32.sin angle],
   [0f32, f32.sin angle,  f32.cos angle]]

let rotateYMatrix (angle: f32): [3][3]f32 =
  [[f32.cos angle,  0f32, f32.sin angle],
   [0f32,           1f32, 0f32],
   [-f32.sin angle, 0f32, f32.cos angle]]

let matmult [n][m][p] (x: [n][m]f32) (y: [m][p]f32): [n][p]f32 =
  map (\xr ->
        map (\yc -> f32.sum (map2 (*) xr yc))
            (transpose y))
      x
\end{lstlisting}
There are several differences between the \fshark{} and the Futhark versions
here. The primary difference is, that the Futhark version supports higher-order
modules. This is shown in line 2 of the Futhark example, where we instantiate
the higher-order 3D vector module \texttt{vec3} with the single precision floating point
type \texttt{f32} module.

\fshark{} does not at this point support similar higher-order modules, so we
fake it by implementing a simple 3D vector module manually.
Then, for both the \fshark{} and the Futhark version, we state a list of type
aliases for the rest of the program.

We then see five functions \texttt{advance\_body}, \texttt{advance\_bodies},
\texttt{advance\_bodies\_steps}, \texttt{wrap\_body} and \texttt{unwrap\_body}.
The differences between the \fshark{} and Futhark versions are negliable, with
one except.
As in the LocVolCalib example, we don't support for-loops in \fshark{}.
Therefore we have replaced the for-loop with a fold instead, obtaining the same functionality. 

Finally, we see five matrix helper functions. For both of the rotation functions
\texttt{rotateXMatrix} and \texttt{rotateYMatrix}, the \fshark{} version infers
the types of the overloaded \texttt{cos} and \texttt{sin} functions
automatically, whereas the Futhark developer must access those two functions
through their containing modules instead.

Also, \fshark{} doesn't have a \texttt{sum} operator in it's standard library
like Futhark has, so we implement it ourselves by defining it in the \fshark{}
version at line 95.

The complete \fshark{} version is available in
appendix~\ref{app:fsharknbody}, with the Futhark version available for reference.

\subsection{Conclusion on \fshark{} language design}
As shown in the two example benchmarks above, we can now write complex GPU
benchmarks in \fsharp{} using purely functional idiomatic \fsharp{}.
We can use nested SOACs as we like, and use records and type aliases to improve
the readibility of the code.

\section{The correctness of the \fshark{} subset.}
\label{subsec:fsharkcorrectness}
To ensure that every operator and function in the \fshark{} subset has
equivalent results, no matter whether the \fshark{} code is run as native
\fsharp{} code, or compiled into Futhark, we have written a comprehensive test suite with unit
tests for each operator, standard library function and SOAC in the \fshark{}
language.

An \fshark{} test is an \fshark{} program, but with two extra values added,
namely an input and an output value for the test. For example, the test written for the
division operator is shown below. It is a unit test for the division operator,
and contains six test cases, namely division for signed integers of (8, 16, 32,
64 bits) and single- and double precision floating points
\begin{minted}[breaklines=true, fontsize=\footnotesize]{fsharp}
module Div
open FSharkPrelude.FSharkPrelude
open FShark.TestTypes.TestTypes
open System

[<FSharkEntry>]
let div (fiveByte : int8) (fiveShort : int16) (five : int) 
        (fiveLong : int64) (fiveSingle : single) (fiveDouble : double) 
        : (int8 * int16 * int * int64 * single * double) =

    (fiveByte / 2y, fiveShort / 2s, five / 2, 
     fiveLong / 2L, fiveSingle / 2.0f, fiveDouble / 2.0)

[<FSharkInput>]
let value = [|5y; 5s; 5; 5L; 5.0f; 5.0|] : obj array

[<FSharkOutput>]
let sameValue = 
  (2y, 2s, 2, 2L, 2.5f, 2.5) : (int8 * int16 * int * int64 * single * double)
\end{minted}
For all arithmetic operators available in \fshark{}, I have written an
accompanying test, suitably located in the directory
\texttt{FSharkTests/UnitTests/Operators} in the \fshark{} project.

We also test that edge cases, such as dividing floating point numbers by zero,
has the correct results (namely \texttt{infinity} or \texttt{-infinity}.)
We also test that \fshark{} inlined functions such (see
section~\ref{sec:rewritess} and~\ref{functionmeaning}) behaves as expected.
The rewritten functions are tested in \texttt{FSharkTests/UnitTests/InlinedFuns}

At the moment, the \fshark{} test suite (\texttt{UnitTests} +
\texttt{FSharkPreludeTests}) contains 128 unit tests, spread across 248 test cases.


\subsection{Testing the \fshark{} standard library}
For the \fshark{} standard library \texttt{FSharkPrelude}, we supply multiple
test suites.
\subsubsection{UnitTests/FSharkSOACS}
The first test suite is located in \texttt{FSharkTests/UnitTests/FSharkSOACS}.
Here, we test various SOAC integrations. The SOACs are not tested
systematically, but are instead mixed and matched with other \fshark{} language
features such as lambdas, to see whether they break when used in more complex ways.  

In example, we use the test \texttt{Filter3}\footnote{\texttt{FSharkTests/UnitTests/FSharkSOACS/Filter/Filter3.fs}} to test whether
Zip, Map, Filter and Unzip, anonymous functions and tuple outputs work well
together, which they do. The test is shown below.
\begin{minted}[fontsize=\scriptsize, breaklines]{fsharp}
module Filter3
open FSharkPrelude.FSharkPrelude
open FShark.TestTypes.TestTypes

[<FSharkEntry>] // original test uses doubles but my CPU doesn't support f64s
let zip1a (xs1 : int array) (xs2 : bool array) : (bool array * int array) =
    let tmp = Filter (fun (x: (int * bool)) ->
                         let (i,b) = x in b
                      ) (Zip xs1 xs2) in
      Unzip(Map (fun (x: (int*bool))  ->
                  let (i,b) = x in (b,i)
               ) tmp)

[<FSharkInput>]
let value = [|[|0;1;-2;5;42|];[|false;true;true;false;true|]|] : obj array

[<FSharkOutput>]
let outvalue = ([|true;true;true|] , [|1;-2;42|]) : (bool [] * int [])
\end{minted}

We do not test all of the Map and Unzip functions, as they are essentially
the same.
For example, we have tested Map and Map2, but as Map3 is designed just
like Map2, but with an extra argument (shown below), we have decided that the
design difference is too small to warrant an extra test case.

\begin{minted}{fsharp}
let Map2 f aa bb =
    let curry f (a,b) = f a b 
    let xs = Zip aa bb
    in Array.map (curry f) xs

let Map3 f aa bb cc =
    let curry f (a,b,c) = f a b c
    let xs = Zip3 aa bb cc
    in Array.map (curry f) xs
\end{minted}

\subsubsection{FSharkPreludeTests}
Besides the \texttt{FSharkSOACS} tests in the \texttt{FSharkTests} folder, the
\texttt{FSharkPrelude} also comes with a test suite on it's own.
We have implemented this test suite to verify that our \fshark{} SOACs have the
same behaviour as their Futhark counterparts.

This test suite contains 53 unit tests of the SOACs in the
\texttt{FSharkPrelude}.
As opposed to the unit tests in the \texttt{FSharkTests}, the unit tests here
doesn't compare their results with the Futhark results, but does instead only
compare their results with a predefined expected result.

Nevertheless, this suite contains 53 test cases spread across all the SOACs, except for near-identical cases, like in the Map2/Map3 example from before.

\subsection{Conclusion on \fshark{} language correctness}
We have written a comprehensive test suite which covers all parts of the \fshark{}
language. All our 248 test cases passes our tests, which makes us confident that
the \fshark{} compiler does indeed translate all parts of the \fshark{} language
correctly to Futhark.
More importantly, our test cases tells us that we can trust that an expression
written in \fshark{} will evaluate to the same result, no matter whether it's
executed in \fsharp{} or in Futhark.

We still have one blind spot though; namely that we haven't written many test
cases for unsigned integers.
These have not been written due to time constraints, but shouldn't be inherently
difficult to add to the existing test suite.

\section{The performance of \fshark{} generated GPU kernels}
\label{sec:fsharkgpubenchmarks}
In the following section, we used the \fshark{} compiler to compile complex GPU
benchmarks written in \fshark{}, to valid Futhark source code.

We have then used the \texttt{futhark-bench} program to run benchmarks on the
\fshark{} generated Futhark code, to compare the \fshark{}-generated Futhark
programs with equivalent handwritten Futhark programs.

The first benchmark tested is the LocVolCalib benchmark.
\subsection{The \texttt{LocVolCalib} benchmark}
In figure~\ref{fig:line-graph} we see the benchmark results of the LocVolCalib benchmark, located in \texttt{FSharkTests/Benchmarks/LocVolCalib.fs}.\\
For the \fsharp{} results in this benchmark, we have used the \texttt{FSharkTests} program in the
\fshark{} repository to first run the compilation, and pass the dataset
arguments to the resulting loaded library.

The first two columns represent the compiled \fshark{} code being executed as
\csharp{} libraries, both with and without OpenCL support.
The third column represents the \fshark{} code being executed natively as
\fsharp{} code.
The three last columns show the benchmark results of the handwritten Futhark
version.

Based on the benchmarks, we can make the following conclusions:
\begin{enumerate}
\item \fshark{} code is significantly faster when compiled to OpenCL than when
  compiled to sequential \csharp{} code. The speed increase is $\times 420$,
  $\times 571$ and $\times 483$ for the small, medium and large dataset respectively.

\item Running \fshark{} code natively in \fsharp{} is slower than compiling the
  \fshark{} code to sequential \csharp{} code.
  This is not surprising, as the Futhark compiler makes various optimizations like fusing SOAC calls during
  compilation, whilst \fsharp{} executes the code as it is written.\\
  The speed increase from native \fshark{} to compiled \fshark{} is $\times 1.06$,
  $\times 1.02$ and $\times 1.51$ for the small, medium and large dataset respectively.

  It is surprising that the \fsharp{} version is not that much slower than
  the compiled \csharp{} version.

\item The \fshark{} version of the LocVolCalib benchmark is significantly slower
  than the already existing Futhark version (upto $\times 2.5$ slower.)
  This is strange, as the two versions are almost the same. We are currently not
  sure why, as the only major difference is the rewriting of Futhark's loop
  expression into a foldl expression (section~\ref{subsec:locvolcalib}).
  We will have to investigate this.

\item The sequential \csharp{} version of the benchmark is up to $\times 37\%$ slower than
  the sequential \csharp{} version. We do not currently know where precisely
  where this slow down appears, but investigating the fact is definitely
  worthwhile. It is our best guess that the speed difference comes from the
  sequential version's array reading and writing functions, as these are
  currently call-by-value, instead of call-by-reference. 
\end{enumerate}

\begin{figure}
    \begin{tikzpicture}
      \begin{axis}[
        title={LocVolCalib performance},
        xlabel={Dataset},
        ylabel={Runtime in milliseconds},
        width=1\textwidth,
        %height=0.5,
        symbolic x coords={small.in,medium.in,large.in},
        xtick=data,
        enlargelimits=0.15,
        ybar=2pt,% configures ‘bar shift’
        bar width=8pt,
        nodes near coords,
        every node near coord/.append style={rotate=70, anchor=west,font=\scriptsize},
        legend style={legend pos=north west}
      ]
      \addplot plot coordinates {(small.in, 187.972) (medium.in, 269.265 ) (large.in, 5052.080 )};
      \addplot plot coordinates {(small.in, 79265 ) (medium.in, 154488 ) (large.in, 2448660 )};
      \addplot plot coordinates {(small.in, 84537 ) (medium.in, 157735 ) (large.in, 3716097 )};
      \addplot plot coordinates {(small.in, 134.032 ) (medium.in, 134.761  ) (large.in,  1925.001 )};
      \addplot plot coordinates {(small.in, 135.192 ) (medium.in, 134.428 ) (large.in, 1911.079 )};
      \addplot plot coordinates {(small.in, 3020.588 ) (medium.in, 5842.482 ) (large.in, 96476.520 )};

      \legend{FShark (OpenCL), FShark (non-OpenCL), FShark executed as FSharp, futhark-bench (futhark-csopencl), futhark-bench (futhark-opencl), futhark-bench (futhark-c)}
      \end{axis}
    \end{tikzpicture}
    \caption{Comparison of LocVolCalib benchmark for multiple versions}
    \label{fig:line-graph}
\end{figure}

\subsection{The \texttt{nbody} benchmark}
Whereas the LocVolCalib benchmark takes nine scalars as input to run, the
\texttt{nbody} benchmark takes multiple arrays of inputs, each containing
thousands of scalars.
We have not implemented a nice way of handling inputs of this size in the
\fshark{} architecture yet.

However, we can still run accurate benchmarks on the \fshark{} version of nbody,
by taking the \fshark{} program out of the \fsharp{} context.

First, we compile the \fshark{} version of nbody to Futhark source code by using
the \fshark{} compiler. Then we add the benchmark annotations
(shown in figure \ref{fig:nbodyannotations})
from the Futhark version of nbody, to the \fshark{} generated version.
Finally, we run the Futhark benchmark program with our code by calling the
command:

\begin{minted}{bash}
$ futhark-bench --compiler=futhark-csopencl fsharkNbody.fut
\end{minted}

Unfortunately, the \texttt{nbody} benchmark is one of the benchmarks that are
affected by the measurement described in section~\ref{sec:errorsinbenchmark}.
Therefore we cannot present a representative comparison between the
\fshark{}/\csharp{} GPU kernel, and it's Futhark/\clang{} counterpart in this report.

However, we can show a runtime comparison between the original Futhark nbody
implementation and the translated \fshark{} version, by running them both with
the Futhark \clang{} OpenCL compiler. We see the results of this benchmark in
figure~\ref{fig:nbodygraphh}.

We see that the \fshark{} version compiles to a Futhark program, that has
performance very close to the original Futhark program.

\subsection{Conclusion on performance of \fshark{} generated GPU kernels}
\label{sec:fsharkgpubenchmarks}
Based on our two benchmarks, we conclude that \fshark{} is indeed a viable GPU
programming language. Although we lose a lot of performance in the LocVolCalib
benchmark, we see no loss of performance in the nbody benchmark.
At this point we cannot safely conclude whether \fshark{} generated Futhark
programs are inherently inferior to Futhark programs.
LocVolCalib says that \fshark{} versions are inferior, and nbody says that they
aren't, so we will have to write more benchmarks before we can make a conclusion
either way.

\begin{figure}
    \begin{tikzpicture}
      \begin{axis}[
        title={nbody performance},
        xlabel={N},
        ylabel={Runtime in microseconds},
        width=1\textwidth,
        %height=0.5,
        symbolic x coords={100,1000,10000,100000},
        xtick=data,
        enlargelimits=0.15,
        ybar=2pt,% configures ‘bar shift’
        bar width=8pt,
        nodes near coords,
        every node near coord/.append style={rotate=70, anchor=west,font=\scriptsize},
        legend style={legend pos=north west}
      ]
      \addplot plot coordinates {(100, 26) (1000,89) (10000,1310) (100000,101401)};
      \addplot plot coordinates {(100, 27) (1000,92) (10000,1306) (100000,101967)};

      \legend{FShark version, Futhark version}
      \end{axis}
    \end{tikzpicture}
    \caption{Two versions of the nbody benchmark compared}
    \label{fig:nbodygraphh}
\end{figure}

\begin{figure}[H]
  \centering
\begin{lstlisting}[language=Futhark, basicstyle=\footnotesize\ttfamily]
-- ==
-- tags { futhark-opencl futhark-c }
--
-- input @ data/nbody-acc-t0.in
-- output @ data/nbody-acc-t0.out
--
-- input @ data/nbody-acc-t10.in
-- output @ data/nbody-acc-t10.out
--
-- input @ data/100-bodies.in
-- input @ data/1000-bodies.in
-- input @ data/10000-bodies.in
-- input @ data/100000-bodies.in

-- "data/N-bodies.in" all have the other attributes n_steps=1, timestep=1.0, and
-- epsilon=50.0.

-- rest of source code goes here
-- ..
\end{lstlisting}
  \caption{Annotations like these shows \texttt{futhark-bench} where it can find
    datasets for its benchmarks}
  \label{fig:nbodyannotations}
\end{figure}


%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End:
