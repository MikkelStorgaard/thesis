\chapter{Background}
In this chapter we will first show two languages for GPU programming, namely
CUDA and Futhark. Then we will show \csharp{} and it's interoperability with
Futhark.
Finally, we will take a look at \fsharp{}, and how we can expect
Futhark/\fsharp{} interoperability.

\section{CUDA}
GPU programming is in principle easily available for everyone. As long as the user has access
to a GPU and a reasonable PC for developing software, it just takes a bit of effort and reading to get started with CUDA, OpenCL or similar programming.
Realistically however, it takes much more than just a little effort to start
writing one's own GPU programs. 

\subsection{A simple CUDA program}
Take for instance the function $f(x,y) = ax+y$. In figure \ref{fig:cudasaxpy} we see the
function implemented as a CUDA program. In this program, we are defining the
kernel \texttt{saxpy} itself, and also manually copying data back and forth
between the GPU.

\begin{figure}[H]
  \centering
\begin{minted}[linenos]{cpp}
  #include <stdio.h>

__global__
void saxpy(int n, float a, float *x, float *y)
{
  int i = blockIdx.x*blockDim.x + threadIdx.x;
  if (i < n){
    y[i] = a*x[i] + y[i];
  }
}

int main(void)
{
  int N = 1<<20;
  float *x, *y, *d_x, *d_y;
  x = (float*)malloc(N*sizeof(float));
  y = (float*)malloc(N*sizeof(float));

  cudaMalloc(&d_x, N*sizeof(float)); 
  cudaMalloc(&d_y, N*sizeof(float));

  for (int i = 0; i < N; i++) {
    x[i] = 1.0f;
    y[i] = 2.0f;
  }

  cudaMemcpy(d_x, x, N*sizeof(float), cudaMemcpyHostToDevice);
  cudaMemcpy(d_y, y, N*sizeof(float), cudaMemcpyHostToDevice);

  // Perform SAXPY on 1M elements
  saxpy<<<(N+255)/256, 256>>>(N, 2.0f, d_x, d_y);

  cudaMemcpy(y, d_y, N*sizeof(float), cudaMemcpyDeviceToHost);

  cudaFree(d_x);
  cudaFree(d_y);
  free(x);
  free(y);
}
\end{minted}
  \caption{$ax + y$ in CUDA}
  \label{fig:cudasaxpy}
\end{figure}

\subsubsection{The CUDA kernel}
Line 3's \texttt{\_\_global\_\_} signifies that the following function is a CUDA kernel.
Line 4 to 10 contains the computational kernel for the GPU.
Line 4 contains the kernels name and arguments. The kernel takes several arguments:
(1) {\tt a} is a scalar constant denoting a multiplicative constant, 
(2) {\tt x} and {\tt y} are references (pointers) to floating point arrays 
    located in GPU-device memory, and 
(3) {\tt n} denotes the length of the arrays {\tt x} and {\tt y}.\\
Line 6 computes the current computational thread's global id {\tt i}. If we compare
a parallel computational kernel with a sequential for-loop, this global id is
the iterator variable.
Line 8 performs the actual $f(x,y)$ calculation, and stores the result in the {\tt y}
array, but only if the if-clause in line 7 is true. 
As we have tens of thousands of threads running simultaneously on the CUDA
device, we only want to perform any array operations if we know that our current
global id is within the length of the array.
\\\\

\subsubsection{The CUDA main function}
We also need a main function to run the kernel:\\
Line 14 sets {\tt N} to $1 << 20$ (or $2^{20}$).\\
Line 16 and 17 allocate memory for two arrays {\tt x} and {\tt y} in host (CPU) memory.\\
Line 19 and 20 allocate memory for two arrays {\tt x} and {\tt y} on the CUDA device (the GPU).\\
Line 22 to 25 initializes the arrays {\tt x} and {\tt y} with scalar values 1.0 and 2.0.\\
Line 27 and 28 copies our arrays from host memory to the corresponding arrays 
{\tt d\_x} and {\tt d\_y}, which are located in (CUDA) device memory.\\
Line 31 spawns a number of threads, each executing the code in the 
\texttt{saxpy} function. The amount and structure of the spawned parallelism 
is defined by the argument denoted by the {\tt <<<g, b>>>} syntax. More precisely,
paramter {\tt b} denotes the number of threads spawned in a block~\footnote{
Separating the parallelism into blocks and grids is useful because the threads
in a block can be synchronized by means of barriers and can communicate with
each other in fast/scratchpad memory. These properties do not hold across threads
in different blocks of the grid. 
}, and parameter
{\tt g} denotes the number of blocks scheduled in a grid.
It follows that the total amount of parallelism
is {\tt g$\times$b}, and that the global thread identifier can be computed
from the position of a thread inside its corresponding grid ({\tt blockIdx.x}) 
and block ({\tt threadIdx.x}), by means of the formula 
{\tt blockIdx.x*blockDim.x + threadIdx.x}.
Finally, the grid and block can have as high as three dimensions each (denoted by 
{\tt .x}, {\tt .y} and {\tt .z}), albeit our example uses a one-dimensional
grid and block (for example {\tt .x}).
\\
Line 33 copies the result from CUDA device back to the y array in the system
memory. \\
The remaining lines frees the allocated memory, first from the CUDA device and
then from the system memory.



\section{Futhark}
Whereas the CUDA program and kernel contained large amounts of memory handling
and bounds checking, a similar program written in Futhark spares us for a lot of
the manual labor above. Figure \ref{fig:futsaxpy} contains a Futhark program
that is semantically equivalent to the CUDA program, in regards to the
computational result.
\begin{figure}[H]
  \centering
\begin{lstlisting}[language=Futhark, numbers=left]
let saxpy (a : f32) (x : f32) (y : f32) : f32 =
  a*x+y

entry main =
  let N = 1<<20
  let a = 2f32
  let xs = replicate N 1f32
  let ys = replicate N 2f32
  let ys' = map2 (saxpy a) xs ys
  in ys'
  \end{lstlisting}
  \caption{$ax+y$ in Futhark}
  \label{fig:futsaxpy}
\end{figure}

Line 1 to 2 defines a function that takes three floats (\textit{a}, \textit{x}
and \textit{y}) and returns $ax+y$.  

Line 4 to 10 defines our main function.\\
In line 4 we use \texttt{entry} instead of \texttt{let} to tell the compiler
that \texttt{main} is an entry point in the compiled program. This means we can
call this function when we import the compiled program as a library, as opposed
to the function \texttt{saxpy}, which cannot be accessed as a library function.\\
Line 5 sets N to $1 << 20$ (or $2^{20}$).\\
Line 6 sets a to 2.0.\\
Line 7 uses the built-in function \texttt{replicate}\footnote{replicate has the
  type \texttt{int -> a -> []a}} to generate an N element
array of 1.0\\
Line 8 uses the built-in function \texttt{replicate} to generate an N element array of 2.0\\
Line 9 uses the built-in function \texttt{map2} to apply the curried function
(\texttt{saxpy a}) to the arrays xs and ys.

\texttt{map f xs} has the type \texttt{((a -> b) -> []a -> []b)}, and
returns the array of f applied to each element of xs.

\texttt{map2 f xs ys} is very similar, but has the type \texttt{((a -> b -> c) -> []a -> []b -> []c)}, and
applies f to the elements of xs and ys pairwise.\\
In this case, we are calling \texttt{map2} with the function \texttt{(saxpy a)},
which is just \texttt{saxpy} with the first argument $a$ already defined.

When we compare the program in figure \ref{fig:cudasaxpy} to the same program
written in Futhark (figure \ref{fig:futsaxpy}), we quickly see how Futhark's
high level declarative approach is simpler and less verbose than CUDA's.
The Futhark compiler does the heavy lifting, by parsing Fuhark source code and
generating OpenCL code and wrapping them in standalone C- or Python programs.

\section{\fsharp{}}
\fsharp{} is a high level multi-paradigm programming language in the .NET family.
\fsharp{}s syntax follows a classical functional programming style. For
instance, this means we can take (some programs) written in Futhark, and port
them to \fsharp{} in a way that very closely resembles the original Futhark
code.

Figure \ref{fig:fsharpsaxpy} shows the Futhark program from
figure \ref{fig:futsaxpy} re-written in \fsharp{}.

\begin{figure}[H]
  \centering
\begin{minted}[linenos]{fsharp}
let saxpy (a : single) (x : single) (y : single) : single =
  a*x+y
  
let main =
  let n = 1<<<20
  let a = 2.0f
  let xs = array.replicate n 1.0f
  let ys = array.replicate n 2.0f
  let ys' = array.map2 (saxpy a) xs ys
  in ys'
  \end{minted}
  \caption{$ax+y$ in Futhark}
  \label{fig:fsharpsaxpy}
\end{figure}

\fsharp{} also supports seamless interoperability with the rest of the .NET 
language family. We can therefore readily use the \csharp{} libraries, which
exports an object-oriented class structure in \fsharp{}, and vice versa.

\section*{\csharp{}}
\csharp{} is an multi-paradigm programming language developed by Microsoft.
In this thesis we implement a Futhark code generator that generates
\csharp{}-integrable GPU code. For this thesis, \csharp{} was chosen for
multiple reasons:
\begin{itemize}
\item \csharp{} is a mainstream programming language, and widely used in
  commercial and academic settings.

\item \csharp{} supports imperative \texttt{C}-style programming, which is
  suitable for writing concrete implementations of programs written in Futhark's
  intermediate language \texttt{ImpCode}, as \texttt{ImpCode}
  itself is an imperative language.
\end{itemize}

%%% Local Variables:
%%% mode: latex
%%% TeX-master: "../thesis"
%%% End:
